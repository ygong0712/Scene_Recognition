{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Dv8absVKufcA",
      "metadata": {
        "id": "Dv8absVKufcA"
      },
      "source": [
        "# Semantic Segmentation with Deep Learning: Training and Testing on Colab\n",
        "\n",
        "Insert the following Javascript snippet into your browser console so that your Colab runtime won't time out. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and type this on the console prompt. (for mac press Option+Command+I)\n",
        "```Javascript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdweXW5Xqd6R",
      "metadata": {
        "id": "bdweXW5Xqd6R"
      },
      "source": [
        "Zip up your code locally with `python zip_for_colab.py`, and upload your `cv_proj5.zip` file. Hit refresh, then run the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ah8PNwYTqM1G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah8PNwYTqM1G",
        "outputId": "7da69a5a-eb1c-4a2a-c9d0-8274111e13e4"
      },
      "outputs": [],
      "source": [
        "!unzip cv_proj5_colab.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0pf627lnqsTo",
      "metadata": {
        "id": "0pf627lnqsTo"
      },
      "source": [
        "Install the `proj6_code` module locally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sEkEfbqNqxa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEkEfbqNqxa4",
        "outputId": "f033af2e-2ddf-4461-c1ff-f6bf9aa57123"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sensitive-franchise",
      "metadata": {
        "id": "sensitive-franchise"
      },
      "source": [
        "Download ImageNet-pretrained ResNet-50:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bound-explosion",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bound-explosion",
        "outputId": "65c88d14-ec29-46ca-8ed6-ebf37ad16bca"
      },
      "outputs": [],
      "source": [
        "!wget -O \"resnet50_v2.pth\" --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w5pRmLJXvmQQA5PtCbHhZc_uC4o0YbmA'\n",
        "!mkdir initmodel && mv resnet50_v2.pth initmodel/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yZDeFtlyuXNz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZDeFtlyuXNz",
        "outputId": "abe3b5b3-1bdb-45fa-9086-d17b4f66b6e6"
      },
      "outputs": [],
      "source": [
        "# The ImageNet-pretrained ResNet-50 weights should be 99 MB\n",
        "!ls -ltrh initmodel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7wzfFzyHupog",
      "metadata": {
        "id": "7wzfFzyHupog"
      },
      "source": [
        "Download the Camvid dataset images. It's 700 MB, but it should only take 30 sec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intellectual-delaware",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "intellectual-delaware",
        "outputId": "d6599992-e192-41d8-a8b7-128f9d1df951"
      },
      "outputs": [],
      "source": [
        "!chmod +rwx camvid_download_dataset.sh\n",
        "!sed -i -e 's/\\r$//' camvid_download_dataset.sh\n",
        "!./camvid_download_dataset.sh Camvid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PGBUoTc9Aj0t",
      "metadata": {
        "id": "PGBUoTc9Aj0t"
      },
      "outputs": [],
      "source": [
        "!ls\n",
        "!cd Camvid && unzip camvid_semseg11.zip && cd .."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "AC_-gfRptGgF",
      "metadata": {
        "id": "AC_-gfRptGgF"
      },
      "source": [
        "We'll now set some default hyperparameters for training. Choose the number of epochs you'd like to train for (for PSPNet, it will take ~30 min for 50 epochs, or ~70 min for 100 epochs). SimpleSegmentationNet will be a bit faster, but make sure to leave enough time to train both models!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "absent-major",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "absent-major",
        "outputId": "89b6a608-73af-47ab-c94e-096183d89e91"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "from types import SimpleNamespace\n",
        "\n",
        "args = SimpleNamespace(\n",
        "    **{\n",
        "        # DATA\n",
        "        \"names_path\": \"camvid_dataset_lists/camvid-11/camvid-11_names.txt\",\n",
        "        \"data_root\": \"Camvid/\",\n",
        "        \"train_list\": \"camvid_dataset_lists/camvid-11/list/train.txt\",  \n",
        "        \"val_list\": \"camvid_dataset_lists/camvid-11/list/val.txt\",\n",
        "        \"classes\": 11,\n",
        "        # TRAIN\n",
        "        \"arch\": \"SimpleSegmentationNet\", #  \"PSPNet\", # SimpleSegmentationNet\n",
        "        \"save_path\": \"\",\n",
        "        \"epochs\": 5,\n",
        "        \"zoom_factor\": 8,\n",
        "        \"use_ppm\": False,   # set to True for PSPNet\n",
        "        \"aux_weight\": 0.4,\n",
        "        \"aux_loss\": False,   # set to True for PSPNet\n",
        "        \"layers\": 50,\n",
        "        \"workers\": 2,\n",
        "        \"batch_size\": 32,\n",
        "        \"batch_size_val\": 32,\n",
        "        \"data_aug\": True,\n",
        "        \"short_size\": 240,\n",
        "        \"train_h\": 201,\n",
        "        \"train_w\": 201,\n",
        "        \"init_weight\": \"./initmodel/resnet50_v2.pth\",\n",
        "        \"scale_min\": 0.5,  # minimum random scale\n",
        "        \"scale_max\": 2.0,  # maximum random scale\n",
        "        \"rotate_min\": -10,  # minimum random rotate\n",
        "        \"rotate_max\": 10,  # maximum random rotate\n",
        "        \"ignore_label\": 255,\n",
        "        \"base_lr\": 0.01,\n",
        "        \"start_epoch\": 0,\n",
        "        \"power\": 0.9,\n",
        "        \"momentum\": 0.9,\n",
        "        \"weight_decay\": 0.0001,\n",
        "        \"manual_seed\": 0,\n",
        "        \"print_freq\": 10,\n",
        "        \"save_freq\": 1,\n",
        "        \"evaluate\": True,  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend\n",
        "        \"multiprocessing_distributed\": False,\n",
        "        # INFERENCE\n",
        "        \"dataset\": \"camvid-11\",\n",
        "        \"base_size\": 240,\n",
        "        \"test_h\": 201,\n",
        "        \"test_w\": 201,\n",
        "        \"scales\": [1.0], # [0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
        "        \"test_list\": \"camvid_dataset_lists/camvid-11/list/val.txt\",\n",
        "        \"vis_freq\": 10,\n",
        "        \"pretrained\": True\n",
        "    }\n",
        ")\n",
        "\n",
        "args.save_path = f\"exp/camvid/{args.arch}/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "increased-blade",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "increased-blade",
        "outputId": "350cafdf-fab5-4846-c481-071291419a6d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "os.makedirs(args.save_path, exist_ok=True)\n",
        "from proj5_code.segmentation.trainer import main_worker\n",
        "print(args)\n",
        "main_worker(args, torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7or_wjTqvX6H",
      "metadata": {
        "id": "7or_wjTqvX6H"
      },
      "source": [
        "We'll now create full-resolution predictions for the full val set, and compute mIoU against the ground truth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worst-vegetation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worst-vegetation",
        "outputId": "374e92e9-64fb-46cc-a950-9a0d653fd303"
      },
      "outputs": [],
      "source": [
        "from proj5_code.segmentation.test import test_model\n",
        "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n",
        "test_model(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ETWCIkf1vfCP",
      "metadata": {
        "id": "ETWCIkf1vfCP"
      },
      "source": [
        "**Important**: Record the mIoU listed in the output above, and the IoU per each class. You can find the results later in `train_epoch_{args.epochs}/camvid-11/240/results.txt`.\n",
        "\n",
        "Now, let's take a look at what our results look like. We'll make a 2x3 image grid with the following structure:\n",
        "\n",
        "|RGB Image | Blended RGB and Ground Truth | Ground Truth \n",
        "|:-: | :-: | :-:\n",
        "| RGB Image | Blended RGB and Prediction | Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cDpIrDQvvBq5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "cDpIrDQvvBq5",
        "outputId": "779e4804-4ce0-4007-f82f-4454bfbcd174"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rgb_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/rgb_mask_predictions\"\n",
        "\n",
        "def show_image_grid(rgb_predictions_dir: str, img_fname: str) -> None:\n",
        "  img_grid = imageio.imread(f'{rgb_predictions_dir}/{img_fname}')\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.imshow(img_grid)\n",
        "  plt.show()\n",
        "\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_07977.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JOxOOpJ-wDHa",
      "metadata": {
        "id": "JOxOOpJ-wDHa"
      },
      "source": [
        "We'll look at more examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wJo0THuZvDkU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wJo0THuZvDkU",
        "outputId": "61716e00-32ab-408b-a005-4426dbc26d28"
      },
      "outputs": [],
      "source": [
        "show_image_grid(rgb_predictions_dir, \"0016E5_07997.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08017.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08037.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08057.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08077.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08097.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08117.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08137.jpg\")\n",
        "show_image_grid(rgb_predictions_dir, \"0016E5_08157.jpg\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "VFCSB5B23t19",
      "metadata": {
        "id": "VFCSB5B23t19"
      },
      "source": [
        "Now, zip up your predictions on the test set for your best SimpleSegmentationNet model, **download them locally to your machine**, and submit these to Gradescope :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VbYbqcNn3eS2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbYbqcNn3eS2",
        "outputId": "abd55052-5551-4636-f762-719696ff9224"
      },
      "outputs": [],
      "source": [
        "grayscale_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/gray\"\n",
        "!ls -ltrh $grayscale_predictions_dir\n",
        "!zip -r grayscale_predictions.zip $grayscale_predictions_dir\n",
        "!ls -ltrh grayscale_predictions.zip"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
